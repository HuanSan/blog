(window.webpackJsonp=window.webpackJsonp||[]).push([[48],{336:function(t,a,s){"use strict";s.r(a);var e=s(10),n=Object(e.a)({},(function(){var t=this,a=t._self._c;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("h1",{attrs:{id:"本地部署-chatglm-6b"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#本地部署-chatglm-6b"}},[t._v("#")]),t._v(" 本地部署 ChatGLM-6b")]),t._v(" "),a("p",[t._v("ChatGLM-6B 是一个开源的、支持中英双语的对话语言模型。基于 General Language Model (GLM) 架构，具有 62 亿参数。结合模型量化技术，用户可以在消费级的显卡上进行本地部署（INT4 量化级别下最低只需 6GB 显存）。")]),t._v(" "),a("p",[t._v("从零环境开始配置")]),t._v(" "),a("h2",{attrs:{id:"_1、安装-python"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_1、安装-python"}},[t._v("#")]),t._v(" 1、安装 python")]),t._v(" "),a("p",[t._v("https://www.python.org/downloads/windows/")]),t._v(" "),a("h2",{attrs:{id:"_2、下载代码"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_2、下载代码"}},[t._v("#")]),t._v(" 2、下载代码")]),t._v(" "),a("p",[a("code",[t._v("git clone https://github.com/THUDM/ChatGLM-6B")])]),t._v(" "),a("p",[t._v("安装依赖")]),t._v(" "),a("p",[a("code",[t._v("pip install -r requirements.txt -i https://mirror.sjtu.edu.cn/pypi/web/simple")])]),t._v(" "),a("h2",{attrs:{id:"_3、安装-pytorch-gpu版"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_3、安装-pytorch-gpu版"}},[t._v("#")]),t._v(" 3、安装 Pytorch(GPU版)")]),t._v(" "),a("p",[t._v("检查是否启用GPU")]),t._v(" "),a("div",{staticClass:"language-py line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-py"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" torch\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("torch"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("__version__"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("   "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#显示Pytorch版本")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("torch"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("cuda"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("is_available"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#返回False为版本不匹配，报该错误；返回Ture，解决问题")]),t._v("\n")])]),t._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[t._v("1")]),a("br"),a("span",{staticClass:"line-number"},[t._v("2")]),a("br"),a("span",{staticClass:"line-number"},[t._v("3")]),a("br")])]),a("h3",{attrs:{id:"_3-1-安装-cuda"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_3-1-安装-cuda"}},[t._v("#")]),t._v(" 3.1 安装 CUDA")]),t._v(" "),a("p",[t._v("查看 NVIDIA 控制面板 => 系统信息 => 驱动程序版本 => 511.81")]),t._v(" "),a("p",[t._v("查看 NVIDIA 对应 CUDA 的版本 "),a("a",{attrs:{href:"https://docs.nvidia.com/cuda/cuda-toolkit-release-notes/index.html",target:"_blank",rel:"noopener noreferrer"}},[t._v("地址"),a("OutboundLink")],1)]),t._v(" "),a("p",[a("a",{attrs:{href:"https://developer.nvidia.com/cuda-toolkit-archive",target:"_blank",rel:"noopener noreferrer"}},[t._v("下载地址"),a("OutboundLink")],1)]),t._v(" "),a("p",[t._v("新建 cmd 命令查看是否安装成功："),a("code",[t._v("nvcc -V")]),t._v("，如果没有还需要配置环境变量")]),t._v(" "),a("p",[a("code",[t._v("C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.6\\bin")])]),t._v(" "),a("h3",{attrs:{id:"_3-2-下载-cudnn"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_3-2-下载-cudnn"}},[t._v("#")]),t._v(" 3.2 下载 cuDNN")]),t._v(" "),a("p",[t._v("需要注册 NVIDIA 账号")]),t._v(" "),a("p",[a("a",{attrs:{href:"https://developer.nvidia.com/rdp/cudnn-archive",target:"_blank",rel:"noopener noreferrer"}},[t._v("下载地址"),a("OutboundLink")],1)]),t._v(" "),a("p",[t._v("下载完成后解压里面的文件夹后复制到对应的 CUDA 中：")]),t._v(" "),a("p",[t._v("复制 /bin 下的文件 到 "),a("code",[t._v("\\CUDA\\v11.6\\bin")])]),t._v(" "),a("p",[t._v("复制 /lib/x64 下的文件 到 "),a("code",[t._v("\\CUDA\\v11.6\\lib\\x64")])]),t._v(" "),a("p",[t._v("复制 /include 下的文件 到 "),a("code",[t._v("\\CUDA\\v11.6\\include")])]),t._v(" "),a("h3",{attrs:{id:"_3-3-安装-pytorch"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_3-3-安装-pytorch"}},[t._v("#")]),t._v(" 3.3 安装 Pytorch")]),t._v(" "),a("p",[t._v("如果已安装还需要卸载 "),a("code",[t._v("pip uninstall torch")])]),t._v(" "),a("p",[t._v("pytorch 网站 https://pytorch.org/get-started/locally/#windows-anaconda")]),t._v(" "),a("p",[t._v("然后再运行命令")]),t._v(" "),a("div",{staticClass:"language-py line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-py"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" torch\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("torch"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("__version__"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("   "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#显示Pytorch版本")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("torch"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("cuda"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("is_available"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#返回False为版本不匹配，报该错误；返回Ture，解决问题")]),t._v("\n")])]),t._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[t._v("1")]),a("br"),a("span",{staticClass:"line-number"},[t._v("2")]),a("br"),a("span",{staticClass:"line-number"},[t._v("3")]),a("br")])]),a("h2",{attrs:{id:"_4、安装-tdm-gcc-cpu上运行"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_4、安装-tdm-gcc-cpu上运行"}},[t._v("#")]),t._v(" 4、安装 TDM-GCC (CPU上运行)")]),t._v(" "),a("p",[a("a",{attrs:{href:"https://jmeubank.github.io/tdm-gcc/",target:"_blank",rel:"noopener noreferrer"}},[t._v("下载地址"),a("OutboundLink")],1)]),t._v(" "),a("p",[t._v("安装 TDM-GCC 时勾选 openmp")]),t._v(" "),a("h2",{attrs:{id:"_5、安装-git-lfs"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_5、安装-git-lfs"}},[t._v("#")]),t._v(" 5、安装 Git LFS")]),t._v(" "),a("p",[t._v("Git LFS 用于下载大文件")]),t._v(" "),a("p",[a("a",{attrs:{href:"https://docs.github.com/zh/repositories/working-with-files/managing-large-files/installing-git-large-file-storage",target:"_blank",rel:"noopener noreferrer"}},[t._v("下载地址"),a("OutboundLink")],1)]),t._v(" "),a("p",[t._v("https://git-lfs.com/")]),t._v(" "),a("h2",{attrs:{id:"_6、配置模型"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_6、配置模型"}},[t._v("#")]),t._v(" 6、配置模型")]),t._v(" "),a("p",[t._v("下载模型实现 "),a("code",[t._v("git clone https://huggingface.co/THUDM/chatglm-6b")])]),t._v(" "),a("p",[t._v("单独下载模型 https://cloud.tsinghua.edu.cn/d/674208019e314311ab5c/")]),t._v(" "),a("p",[t._v("可在更目录下创建 chatglm-6b 或其他模型目录")]),t._v(" "),a("p",[t._v("然后配置模型目录：")]),t._v(" "),a("div",{staticClass:"language-py line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-py"}},[a("code",[t._v("tokenizer "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" AutoTokenizer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("from_pretrained"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"chatglm-6b-int4"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" trust_remote_code"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# chatglm-6b-int4 为模型目录")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# model = AutoModel.from_pretrained("chatglm-6b", trust_remote_code=True).half().cuda() # 使用GPU')]),t._v("\nmodel "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" AutoModel"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("from_pretrained"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"chatglm-6b-int4"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("trust_remote_code"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("float")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 使用CPU")]),t._v("\n")])]),t._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[t._v("1")]),a("br"),a("span",{staticClass:"line-number"},[t._v("2")]),a("br"),a("span",{staticClass:"line-number"},[t._v("3")]),a("br")])]),a("h2",{attrs:{id:"_7、运行"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_7、运行"}},[t._v("#")]),t._v(" 7、运行")]),t._v(" "),a("p",[a("code",[t._v("python web_demo.py")])]),t._v(" "),a("div",{staticClass:"img-page"},[a("a",{attrs:{"data-fancybox":"",title:"web-demo",href:"/blog/img/article/python/1.png"}},[a("img",{attrs:{src:t.$withBase("/img/article/python/1.png"),alt:"web-demo"}})])]),t._v(" "),a("h2",{attrs:{id:"_8、参考"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_8、参考"}},[t._v("#")]),t._v(" 8、参考")]),t._v(" "),a("p",[t._v("https://github.com/THUDM/ChatGLM-6B")]),t._v(" "),a("p",[t._v("https://www.heywhale.com/mw/project/6436d82948f7da1fee2be59e")]),t._v(" "),a("p",[t._v("https://huggingface.co/THUDM")]),t._v(" "),a("p",[t._v("https://blog.csdn.net/moyong1572/article/details/119438286")]),t._v(" "),a("p",[t._v("https://blog.csdn.net/qq_46941656/article/details/119701547")]),t._v(" "),a("p",[t._v("https://blog.csdn.net/sinat_24948419/article/details/105532537")]),t._v(" "),a("p",[t._v("https://zhuanlan.zhihu.com/p/479848495")]),t._v(" "),a("p",[t._v("https://zhuanlan.zhihu.com/p/535100411")])])}),[],!1,null,null,null);a.default=n.exports}}]);